# -*- coding: utf-8 -*-
"""Projectcode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CyrTz4_qYvcXG1eAQGDZ1qa-ir9qUl9c
"""

# Air Quality Prediction using Sample Dataset

# Step 1: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 2: Load the Sample Dataset
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/large_air_quality_dataset-1.csv")

# Step 3: Separate Features and Target
X = df.drop('Air_Quality_Level', axis=1)
y = df['Air_Quality_Level']

# Step 4: Encode Target Labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Step 5: Normalize the Features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 6: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)

# Step 7: Train Models

# Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

# XGBoost
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)

# Step 8: Evaluate Models
print("Random Forest Accuracy:", accuracy_score(y_test, rf_pred))
print("Random Forest Classification Report:\n", classification_report(y_test, rf_pred, target_names=le.classes_))

print("\nXGBoost Accuracy:", accuracy_score(y_test, xgb_pred))
print("XGBoost Classification Report:\n", classification_report(y_test, xgb_pred, target_names=le.classes_))

# Step 9: Visualize Confusion Matrix - Random Forest
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, rf_pred), annot=True, fmt='d',
            xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Step 10: Visualize Feature Importance - Random Forest
importances = rf_model.feature_importances_
plt.figure(figsize=(10, 6))
sns.barplot(x=importances, y=X.columns)
plt.title("Feature Importance - Random Forest")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

!pip install gradio

# Air Quality Prediction and Gradio Deployment (All-in-One)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import gradio as gr
import joblib

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Load the Dataset
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/large_air_quality_dataset-1.csv")  # Ensure the CSV is in the same directory

# Step 2: Prepare Features and Target
X = df.drop('Air_Quality_Level', axis=1)
y = df['Air_Quality_Level']

# Step 3: Encode target labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Step 4: Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)

# Step 6: Train Random Forest Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Step 7: Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=le.classes_))

# Step 8: Save Model Artifacts
joblib.dump(model, "rf_model.pkl")
joblib.dump(scaler, "scaler.pkl")
joblib.dump(le, "label_encoder.pkl")

# Step 9: Gradio Interface for Deployment
def predict_air_quality(pm25, pm10, no2, co, o3, so2, temp, humidity, windspeed):
    model = joblib.load("rf_model.pkl")
    scaler = joblib.load("scaler.pkl")
    le = joblib.load("label_encoder.pkl")

    features = np.array([[pm25, pm10, no2, co, o3, so2, temp, humidity, windspeed]])
    scaled = scaler.transform(features)
    prediction = model.predict(scaled)
    label = le.inverse_transform(prediction)[0]
    return label

# Define Gradio UI
inputs = [
    gr.Number(label="PM2.5"),
    gr.Number(label="PM10"),
    gr.Number(label="NO2"),
    gr.Number(label="CO"),
    gr.Number(label="O3"),
    gr.Number(label="SO2"),
    gr.Number(label="Temperature (°C)"),
    gr.Number(label="Humidity (%)"),
    gr.Number(label="Wind Speed (m/s)")
]
output = gr.Textbox(label="Predicted Air Quality Level")

# Launch Gradio App
app = gr.Interface(fn=predict_air_quality, inputs=inputs, outputs=output, title="Air Quality Level Predictor")
app.launch()

!pip install Gradio

# Air Quality Prediction and Gradio Deployment (All-in-One)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import gradio as gr
import joblib

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Load the Dataset
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/large_air_quality_dataset-1.csv")  # Ensure the CSV is in the same directory

# Step 2: Prepare Features and Target
X = df.drop('Air_Quality_Level', axis=1)
y = df['Air_Quality_Level']

# Step 3: Encode target labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Step 4: Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)

# Step 6: Train Random Forest Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Step 7: Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=le.classes_))

# Step 8: Save Model Artifacts
joblib.dump(model, "rf_model.pkl")
joblib.dump(scaler, "scaler.pkl")
joblib.dump(le, "label_encoder.pkl")

# Step 9: Gradio Interface for Deployment
def predict_air_quality(pm25, pm10, no2, co, o3, so2, temp, humidity, windspeed):
    model = joblib.load("rf_model.pkl")
    scaler = joblib.load("scaler.pkl")
    le = joblib.load("label_encoder.pkl")

    features = np.array([[pm25, pm10, no2, co, o3, so2, temp, humidity, windspeed]])
    scaled = scaler.transform(features)
    prediction = model.predict(scaled)
    label = le.inverse_transform(prediction)[0]
    return label

# Define Gradio UI
inputs = [
    gr.Number(label="PM2.5"),
    gr.Number(label="PM10"),
    gr.Number(label="NO2"),
    gr.Number(label="CO"),
    gr.Number(label="O3"),
    gr.Number(label="SO2"),
    gr.Number(label="Temperature (°C)"),
    gr.Number(label="Humidity (%)"),
    gr.Number(label="Wind Speed (m/s)")
]
output = gr.Textbox(label="Predicted Air Quality Level")

# Launch Gradio App
app = gr.Interface(fn=predict_air_quality, inputs=inputs, outputs=output, title="Air Quality Level Predictor")
app.launch()